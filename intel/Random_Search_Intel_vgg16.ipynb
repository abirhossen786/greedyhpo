{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2,keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.tuners import Hyperband\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_random_image(target_dir, target_class):\n",
    "    target_folder = target_dir + target_class\n",
    "    random_image = random.sample(os.listdir(target_folder), 1)\n",
    "    img = mpimg.imread(target_folder+'/'+random_image[0])\n",
    "    plt.imshow(img)\n",
    "    plt.title(target_class)\n",
    "    plt.axis('off');\n",
    "    #print(f\"Image shape {img.shape}\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "class_names=['buildings', 'forest', 'glacier', 'mountain' ,'sea' ,'street']\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(18):\n",
    "    plt.subplot(3, 6, i+1)\n",
    "    class_name = random.choice(class_names)\n",
    "    img = view_random_image(target_dir='/home/abir/Downloads/greedyhpo/intel/archive/seg_train/seg_train/',target_class=class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/home/abir/Downloads/greedyhpo/intel/archive/seg_train/seg_train\"\n",
    "test_dir = \"/home/abir/Downloads/greedyhpo/intel/archive/seg_test/seg_test\"\n",
    "val_dir =\"/home/abir/Downloads/greedyhpo/intel/archive/seg_val/seg_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_data = train_data.flow_from_directory(train_dir,\n",
    "                                              batch_size = 32,\n",
    "                                              target_size = (32,32), \n",
    "                                              class_mode = 'categorical')\n",
    "\n",
    "val_data = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "validation_data = val_data.flow_from_directory(val_dir,\n",
    "                                            batch_size = 32,\n",
    "                                            target_size = (32,32), \n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "\n",
    "test_data = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "testing_data = test_data.flow_from_directory(test_dir,\n",
    "                                            batch_size = 32,\n",
    "                                            target_size = (32,32), \n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = f\"{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(hp.Choice('layer_size_1', values=[16,32,64,128,256,512],default=16), 3, activation='relu', padding = 'same', input_shape=(32, 32, 3),kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dropout(hp.Choice('dp_size_1', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Conv2D(hp.Choice('layer_size_1', values=[16,32,64,128,256,512],default=16), 3, activation='relu', padding = 'same',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    #####################################Block 2#################################         \n",
    "    model.add(Conv2D(hp.Choice('layer_size_2', values=[16,32,64,128,256,512],default=16), 3,padding ='same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dropout(hp.Choice('dp_size_2', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Conv2D(hp.Choice('layer_size_2', values=[16,32,64,128,256,512],default=16), 3,padding ='same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    ######################################Block 3#################################            \n",
    "    model.add(Conv2D(hp.Choice('layer_size_3', values=[16,32,64,128,256,512],default=16), 3, padding = 'same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dropout(hp.Choice('dp_size_3', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Conv2D(hp.Choice('layer_size_3', values=[16,32,64,128,256,512],default=16), 3, padding = 'same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dropout(hp.Choice('dp_size_3', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Conv2D(hp.Choice('layer_size_3', values=[16,32,64,128,256,512],default=16), 3, padding = 'same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    ######################################Block 4################################\n",
    "    model.add(Conv2D(hp.Choice('layer_size_4', values=[16,32,64,128,256,512],default=16), 3, padding = 'same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dropout(hp.Choice('dp_size_4', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Conv2D(hp.Choice('layer_size_4', values=[16,32,64,128,256,512],default=16), 3, padding = 'same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dropout(hp.Choice('dp_size_4', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Conv2D(hp.Choice('layer_size_4', values=[16,32,64,128,256,512],default=16), 3, padding = 'same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    ######################################Block 5#################################\n",
    "    model.add(Conv2D(hp.Choice('layer_size_5', values=[16,32,64,128,256,512],default=16), 3, padding = 'same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dropout(hp.Choice('dp_size_5', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Conv2D(hp.Choice('layer_size_5', values=[16,32,64,128,256,512],default=16), 3, padding = 'same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dropout(hp.Choice('dp_size_5', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Conv2D(hp.Choice('layer_size_5', values=[16,32,64,128,256,512],default=16), 3, padding = 'same', activation='relu',kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "    ############################################################################\n",
    "    model.add(Dropout(hp.Choice('dp_size_6', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(hp.Choice('dense_size_1', values=[64,128,256,512],default=64),activation=\"relu\",kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dense(hp.Choice('dense_size_2', values=[64,128,256,512],default=64),activation=\"relu\",kernel_regularizer=regularizers.l2(hp.Choice('wd_size_1', values=[0.0,0.1, 0.001, 0.0001],default=0.0))))\n",
    "    model.add(Dropout(hp.Choice('dp_size_6', values=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],default=0.0)))\n",
    "    model.add(Dense(units=6, activation=\"softmax\"))\n",
    " ##############################################################################           \n",
    "    \n",
    "    opt = Adam(lr=hp.Choice('learning_rate', values=[1e-1,1e-2, 1e-3, 1e-4, 1e-5],default=1e-2))\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                                                  optimizer=opt,\n",
    "                                                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=87,  # how many model variations to test?\n",
    "        executions_per_trial=1,  # how many trials per variation? (same model could perform differently)\n",
    "        directory=LOG_DIR,\n",
    "        project_name='RS_Vgg16_Cifar10')\n",
    "\n",
    "    tuner.search_space_summary()\n",
    "    my_callbacks = [ tf.keras.callbacks.EarlyStopping(patience=3)]\n",
    "    tuner.search(training_data,\n",
    "                 verbose=1, # just slapping this here bc jupyter notebook. The console out was getting messy.\n",
    "                 epochs=100,\n",
    "                 batch_size=64,\n",
    "                 callbacks=[my_callbacks],  # if you have callbacks like tensorboard, they go here.\n",
    "                 validation_data=validation_data)\n",
    "\n",
    "    tuner.results_summary()\n",
    "\n",
    "    with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(tuner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    hist=model.fit(training_data,\n",
    "          batch_size=64,\n",
    "          epochs=100,\n",
    "          validation_data=validation_data,\n",
    "          callbacks=[my_callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,test_acc = model.evaluate(testing_data[0][0],testing_data[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
