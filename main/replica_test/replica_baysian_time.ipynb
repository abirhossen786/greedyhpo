{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2,keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import initializers\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 81.1 ms\n"
     ]
    }
   ],
   "source": [
    "MEMORY_LIMIT = 4800\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=MEMORY_LIMIT)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99.3 ms\n"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 76.8 ms\n"
     ]
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 69.7 ms\n"
     ]
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 61.6 ms\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 70.5 ms\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = f\"{int(time.time())}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 339 ms\n"
     ]
    }
   ],
   "source": [
    "#from keras.datasets import cifar10\n",
    "# load dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 158 ms\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = X_train / 255.0, X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.1 ms\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (5, 5),strides = [1,1], input_shape=(28, 28, 1),padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3),padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    global bs\n",
    "    \n",
    "    bs = hp.Choice('batch_size', values=[32,48,64,96,128],default=32)\n",
    "\n",
    "    opt = SGD(lr=hp.Choice('learning_rate', values=[1e-1,1e-2, 1e-3, 1e-4, 1e-5],default=1e-3))\n",
    "    model.compile(\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'],\n",
    "                  )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 04m 24s]\n",
      "val_accuracy: 0.9901999831199646\n",
      "\n",
      "Best val_accuracy So Far: 0.9919000267982483\n",
      "Total elapsed time: 03h 45m 26s\n",
      "Results summary\n",
      "Results in 1627404018/BS_MINIST\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.9919000267982483\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.9919000267982483\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.9915000200271606\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.9914000034332275\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.9914000034332275\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.9912999868392944\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.9912999868392944\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.9912999868392944\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.9912999868392944\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "batch_size: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.991100013256073\n",
      "time: 3h 45min 26s\n"
     ]
    }
   ],
   "source": [
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=50,  # how many model variations to test?\n",
    "    executions_per_trial=1,  # how many trials per variation? (same model could perform differently)\n",
    "    directory=LOG_DIR,\n",
    "    project_name='BS_MINIST')\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "my_callbacks = [ tf.keras.callbacks.EarlyStopping(patience=3)]\n",
    "\n",
    "tuner.search(x=X_train,\n",
    "             y=y_train,\n",
    "             verbose=1, # just slapping this here bc jupyter notebook. The console out was getting messy.\n",
    "             epochs=10,\n",
    "             batch_size=bs,\n",
    "             callbacks=[my_callbacks],  # if you have callbacks like tensorboard, they go here.\n",
    "             validation_data=(X_test,y_test))\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tuner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
